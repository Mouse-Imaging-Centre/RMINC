\documentclass{report}
\usepackage{Sweave}
\usepackage{url}
\usepackage{makeidx}
\usepackage{subfigure}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\makeindex

\begin{document}


\begin{titlepage}
\begin{center}
 
 
% Upper part of the page
%\includegraphics[width=0.15\textwidth]{./logo}\\[1cm]
 
%\textsc{\LARGE University of Beer}\\[1.5cm]
 
%\textsc{\Large Final year project}\\[0.5cm]
 
 
% Title
\HRule \\[0.4cm]
{ \huge \bfseries Structural MRI statistics using RMINC v0.5}\\[0.4cm]
 
\HRule \\[1.5cm]
 
% Author and supervisor
\begin{minipage}{0.4\textwidth}
%\begin{flushleft} \large
\begin{center}
\emph{Author:}\\
Jason \textsc{Lerch}
\end{center}
%\end{flushleft}
\end{minipage}
%\begin{minipage}{0.4\textwidth}
%\begin{flushright} \large
%\emph{Supervisor:} \\
%Dr. Mark \textsc{Brown}
%\end{flushright}
%\end{minipage}
 
\vfill
 
% Bottom of the page
{\large \today}
 
\end{center}
\end{titlepage}



\chapter*{Preface}
This mini-book attempts to provide a general introduction to the
statistics side of structural brain imaging, with a heavy emphasis on
practical worked examples. It also introduces a particular toolkit,
RMINC, designed to make running these types of statistical analyses
easier. It is targeted at the general user, who may or may not have
some statistical background, but does have some data they want
analysed in a straightforward way. It is not meant to be a complete
handbook on statistics, but hopefully will provide enough of a primer
to get by, at least for a little while. 

This mini-book exists for a number of reasons. I have over the years
been asked multiple questions relating to structural brain imaging and
statistics, and have had the chance to learn answers to those
questions from countless people. This book thus exists as an attempt
to put some of those answers down on paper. Secondly, writing this
book is part and parcel of the development of RMINC; it is easier to
write code useable by others if one documents it first, and then
writes code to fit the documentation.

The book will likely be an incomplete work in progress for a long
while yet. The \LaTeX source for this book are packaged along with
RMINC itself, and contributors are most welcome!


\tableofcontents
%\listoffigures
%\listoftables


\chapter{Introduction}
The process of analysing brain imaging data is typically comprised of
a series of stages. The study is designed with various choices made
about the biology question that is to be addressed and the data
necessary to answer the questions thus posed. Then the data is then
acquired, and once that is completed, the images are processed in
various automatic, semi-automatic, or manual ways and then analysed. 

This book deals mainly with the final part, the data analysis, though
there will be several side-tracks into the other topics. A single
example will be used throughout: a mouse brain imaging study comparing
male to female mouse brains. The methods described herein should be
easily transferable to any other structural imaging study which looks
at brain shape, tissue classification, or signal intensities.


\section{Installing the tools}
All the analyses will be performed using RMINC, which is a library
designed to handle MINC\index{MINC} volumes inside the R\index{R}
statistical environment. All the tools needed are freely available,
and should run on just about any computer/operating
system. Installation and setup is described in some more detail below.


\subsection{R}
Quick background about R.

Installing R.

Where to find further reading.


\subsection{MINC}
Quick background about MINC.

In order for RMINC to work, the MINC libraries have to be compiled as
shared libraries. When configuring, make sure the following flag is added on:

\begin{verbatim}
./configure --enable-shared=yes
\end{verbatim}

Where to find more information.


\subsection{RMINC}
Quick background about RMINC.

Installing RMINC.


\section{Overview of the analysis process}
The data analysis process usually proceeds in the following way. First
the input images are assessed for correctness; any obvious processing
errors are removed from any subsequent analyses. The question of what
constitutes an outlier is often a tricky one. In order to avoid the
temptation to manipulate the data in a biased way it is best if the
person who reviews the input data is blind about the categorization of
each particular dataset.

Once all the acceptable datasets are in place a series of descriptive
statistics can be generated, usually consisting of means and standard
deviations of all images in the study as well as of all the
subgroupings. This is followed by generating statistical maps of the
main variables of interest. These are then thresholded for
significance while taking multiple comparisons into account. There is
then often a series of steps in which new statistical models are
analyzed and thresholded until the results become more
understandable. This usually involves lots of plotting of individual
datapoints.

% This book will cover those topics in turn in the following
% chapters. Chapter \ref{chp:input} describes the prepartion of the data
% for analysis, chapter \ref{chp:descriptive} shows how to run
% descriptive statistics, chapter \ref{chp:group} talks about performing
% group comparisons and ANOVAs, chapter \ref{chp:ancova} gets into the topic of
% correlations, regressions, and ANCOVAs, chapter \ref{chp:multiple}
% addresses the issue of multiple comparisons, and chapter
% \ref{chp:plotting} describes how to plot individual datapoints.


\section{Data used throughout this book}
This book will consistently work with one dataset consisting of 5 male
and 5 female C57Bl/6 mice, taken from a larger dataset published in a
2007 NeuroImage paper by Spring et al. The mice, all 12 weeks old,
were scanned using an overnight T2-weighted FSE sequence, then all
aligned into a common space using an automated image registration
algorithm (i.e. deformation based morphometry). The final metric of
interest was then the Jacobian determinant of the deformations needed
to align each mouse to the final common atlas. These details are
relatively unimportant for this book - the input might as well be
voxel density maps from VBM - but at least it gives some background
for those who care. If you want to follow along with the examples used
in this book you can download the data at
\url{http://launchpad.net/rminc}. Note that the data has been
downsampled to 120 micron voxels (from the original 32 micron voxels)
to keep the download within reasonable limits.


\chapter{Preparing the data}
This chapter will briefly discuss how to generate structural imaging
data useable for the statistical analyses described in the rest of the
book.


\section{Types of datasets}
Describe what can be done.


\subsection{Voxel based morphometry}
Some more detail on VBM.


\subsection{Deformation based morphometry}
Some more detail on DBM.


\subsection{Other}
Mention cortical thickness, manual segmentation, etc.


\section{Input data}
Once the files have been processed, the easiest way to proceed is by
settting up a text file containing all the necessary information about
each scan. This file should be comma or space separated, have one row
per scan, with each column containing info about each scan. One of the
columns should contain the filename pointing to the MINC volumes to be
processed. The example from the five male and five female mice is the
following: 

\begin{verbatim}
Filename, Gender, coil, weight
volumes/img_08nov05.0-fwhm1.0.mnc,Female,1,22.6
volumes/img_08nov05.1-fwhm1.0.mnc,Female,2,19.6
volumes/img_08nov05.2-fwhm1.0.mnc,Female,3,21.8
volumes/img_29sept05.0-fwhm1.0.mnc,Male,1,24.0
volumes/img_29sept05.2-fwhm1.0.mnc,Male,3,27.0
volumes/img_30sept05.0-fwhm1.0.mnc,Male,1,28.3
volumes/img_30sept05.1-fwhm1.0.mnc,Male,2,26.5
volumes/img_30sept05.2-fwhm1.0.mnc,Male,3,28.1
volumes/img_31oct05.0-fwhm1.0.mnc,Female,1,20.5
volumes/img_31oct05.2-fwhm1.0.mnc,Female,3,20.0
\end{verbatim}

Notice how the first row contains a header. This is optional, but
makes later access to the data easier and is therefore recommended.

The next step is to actually load this file into R. The steps are
given below:

<<echo=FALSE>>=
options(width=60)

# get path to volumeData subdir within package
volDir <- system.file("packageData/volumes", package="RMINC")
dataDir <- system.file("packageData", package="RMINC")

library(xtable)
@


<<intro>>=
options(warn=0)
library(RMINC)
inputFile <- file.path(dataDir, "control-file.csv")
gf <- read.csv(inputFile)
@

The library commands load the RMINC library into R. The next line then
reads the information describing this dataset from a comma-separated
text file. The basic syntax of an R command is a variable name - which
can be whatever you chose, within only a few limits - on the left hand
side, the arrow (less than followed by a dash) indicating an
assignment, and then the function call (in this case read.csv to read
a comma separated value) with any arguments (in this case the
filename) in parentheses. Strings - such as the filename in this case
- are placed inside quotes.

<<table,results=tex>>=
xtable(gf, caption="GLIM File")
@ 

The little code fragment and table above just shows what the gf variable looks like after being read into R\footnote{xtable is only necessary for display purposes in this manual (which, by the way, is being written using Sweave, a tool for combining R with latex).} 



\chapter{Descriptive statistics}
Before going into explicit hypothesis tests it is often useful to get
a general feel for what the data looks like - this is where
descriptive statistics come in. The most common functions include
computing the mean and variance or standard deviation at every
voxel. If the data is inherently divided into groups, such as patients
and control, or, in our example dataset, males versus females, then
the descriptive stats can also be grouped by those variables.

To start we can look at the mean Jacobian determinant at every voxel
of all the data combined:

<<>>=
setwd(dataDir)
overall.mean <- mincMean(gf$Filename)
overall.mean
@ 

The \texttt{mincMean} function computes the mean at every voxel of a
set of filenames specified as an argument. The output is in this case
assigned to the \texttt{overall.mean} variable. Repeating the variable
in the R session, as done above, causes a summary to be printed.

One thing to note about the R syntax above: the dollar symbol is used
to access a specific column inside a data frame. What this means is
that inside the \texttt{gf} variable - which, remember, is the
variable that was read in from the comma-separated values file which
describes the dataset - each column has a name which can be accessed
by that dollar variable. Here are some examples, first showing the
entire contents of \texttt{gf} and then two separate columns alone:

<<>>=
gf
gf$Filename
gf$Gender
@ 

So if, in the text file that describes the dataset, the column containing all the filenames was called ``jacobians'', then the \texttt{mincMean} command would have been \texttt{mincMean(gf\$jacobians)}.  If an incorrect column is specified - i.e. something which does not contain filenames - then you should receive an error.


\section{Writing results to file}
Once the means at every voxel have been computed, they can be written
to file. This is done with command below:

<<>>=
outDir <- "/tmp"
outFilename <- "overall-mean.mnc"
outFullFilename <- file.path(outDir, outFilename)
mincWriteVolume(overall.mean, outFullFilename)
@ 

The \texttt{mincWriteVolume} command takes two arguments in the above
example - the variable containing the data, and a string giving the
filename to which the data should be written to. This MINC file can
then be read and viewed with the standard MINC tools such as mincinfo,
register, Display, etc.


\section{Creating summaries by group}
Most often we are more interested in how the means break down by the
grouping in this dataset. This can be done by adding another variable
to the mincMean call:

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
group.means <- mincMean(gf$Filename, gf$Gender)
group.means
@ 

The {\em Gender} variable has two levels in it: {\em Male} and {\em
  Female}. So it will take the mean for all subjects in each group. These
can then be written to file by specifiying the column.

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
fileOut <- file.path("/tmp", "male-mean.mnc")
mincWriteVolume(group.means, fileOut, "Male")
#
fileOut <- file.path("/tmp", "female-mean.mnc")
mincWriteVolume(group.means, fileOut, "Female")
@

If the difference between the two columns is of interest, one can just
subtract the two data columns and then write out the result as a new minc volume.

<<echo=TRUE, keep.source=TRUE, eval=FALSE>>=
setwd(dataDir)
difference <- group.means[,"Male"] - group.means[,"Female"]
mean(difference)
#
fileOut <- file.path("/tmp", "diff.mnc")
likeFile <- gf$Filename[1]
mincWriteVolume(difference, fileOut, likeFile)
@

Notice how {\em mincWriteVolume} now needs a third argument: the name
of a minc-file which has the same dimensions as the data. By default
commands such as {\em mincMean} will store that information; after the
subtraction above, however, the result is just a series of numbers
with all metadata removed, so it has to be specified when writing the
data to file.

Of course means are not the only items of interest. Also computable
are the standard-deviations, variances, and sums, as illustrated
below. Just like {\em mincMean} a column of filenames is required and
a grouping variable is optional.

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
volVariance <- mincVar(gf$Filename, gf$Gender)
volStdDev <- mincSd(gf$Filename)
volSum <- mincSum(gf$Filename, gf$Gender)
@ 



\chapter{Linear Models}
Linear models represent the mainstay of structural brain
imaging. Their essence is quite simple: the data at every voxel is
modelled by a set of terms corresponding to extra information about
each scan. One can then perform hypothesis tests on each linear model
to calculate the significance of either the entire model or even the
marginal significance of each term in the model. This can be used to
ask the question of, for example, in which voxels the gender of the
subject predicts the values at that voxel.

This approach is also known as {\em massively univariate statistics} -
i.e. a separate linear model is calculated at every voxel, resulting
in thousands or even millions of separate models for every statistical
test applied to the images. The last step in analysing such data is
thus often to account for these thousands of comparisons so that the
results do not occur just by random chance.


\section{First linear model}
Let's start with a simple linear model - lets see where the Jacobian
determinants contained in the files used in the male-female dataset
are best modelled by the gender of the mouse.

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
vs <- mincLm(Filename ~ Gender, gf)
print(vs)
#
fileOut <- file.path("/tmp", "simple-lm.mnc")
mincWriteVolume(vs, fileOut, "GenderMale")
@ 

mincLm is the command to run linear models in RMINC. Its basic use is
to provide a formula (same syntax as the R \texttt{lm} command) with
the left side containing the filenames, the right side the variables
to be regressed. The output of mincLm depends on the formula. There
will always be a column of F-statistics, representing the significance
of the entire model. Then there is one column for each of the terms in
the model. The above linear model, relating the Jacobian determinant to
gender, will thus have three columns:

\begin{description}
\item[F-statistic] representing the significance of the entire model.
\item[(Intercept)] the intercept term - this term is rarely
  interesting, as it tests for whether the intercept is 0. There's no
  reason to believe it should be in most cases, so this value will be
  highly significant but meaningless.
\item[GenderMale] the term testing whether the ``Male'' level of the
  Gender factor is significant. In this case this term is the most
  interesting and therefore the one written to file.
\end{description}

The output is placed into a variable that can be written to file in
the same way as described in the descriptive statistics section. 


\section{Plotting voxels}

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
options(show.signif.stars=FALSE)
voxel <- mincGetVoxel(gf$Filename, 44, 20, 52)
summary(lm(voxel ~ Gender, gf))
vs[635093,]
@ 

The code above does the following: it gets the voxel from coordinates
44, 20, 52 for all subjects, then computes a linear model relating
that voxel to Genotype using standard R functions. Lastly it prints
the results from that same voxel as computed by
\texttt{mincLm}\footnote{The actual number indexed here - 635093 -
  might appear odd. RMINC treats all MINC volumes as 1-dimensional
  arrays, so the actual index has to be computed by the following
  formula: $\left(index_1 * size_2 + index_2\right) + size_3 +
  index_3$}. This helps illustrate what the output of \texttt{mincLm}
stores: the F-statistic is the same as can be found in the last line
of the summary command, and the t-statistics for the Intercept and
Genotype column can be found under "t-value" when using standard R
functions.

\texttt{mincGetVoxel} needs three coordinates, given in voxel space in
the same order as stored in the file. Just printing the voxel will
show the corresponding world coordinates:

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
print(voxel)
@ 

If the coordinates are specified in world coordinates then
\texttt{mincGetWorldVoxel} is what you want - it also takes three
coordinates, this time in world space in xspace,yspace,zspace order:

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
world.voxel <- mincGetWorldVoxel(gf$Filename, -3.6, -3.9, -1.5)
world.voxel
@ 


\section{Creating images}
RMINC has the ability to call ray\_trace to create images of individual
slices corresponding to a specific voxel. For this to work
ray\_trace\footnote{\url{http://packages.bic.mni.mcgill.ca}} has to be
installed and present in the path, as does
MICe-minc-tools\footnote{\url{http://wiki.phenogenomics.ca:8080/display/MICePub/MICe-minc-tools}}. 

An example is given below - this will create an image of the slice
corresponding to the voxel location along with a cross-hair over that
voxel. The output can be seen in figure \emph{ref{ray-trace-img}}, along
with a box-and-whiskers plot of the data at that voxel.

<<echo=TRUE, keep.source=TRUE, eval=FALSE>>=
mincRayTraceStats(voxel, "volumes/anatomy.mnc",
                  vs, "GenderMale", image.min=350000, image.max=1.0e+06,
                  display=F)
@ 

The \texttt{mincRayTraceStats} function needs the following arguments:
a voxel, obtained by mincGetVoxel or mincGetWorldVoxel, the path
towards a MINC image containing some background anatomy, the output of
mincLm (vs in this case), and minimum and maximum values of the
background anatomy.

% \begin{figure}
% \begin{minipage}[b]{0.5\linewidth}
% \centering
% \includegraphics[width=2.5in]{ray_trace_crosshair.png}
% \caption{Ray-traced slice}
% \label{ray-trace-img}
% \end{minipage}
% \begin{minipage}[b]{0.5\linewidth}
% \centering
% <<fig=T, echo=F>>=
% plot(voxel ~ Gender, gf)
% @ 
% \caption{Box and whiskers plot from cursor location}
% \end{minipage}
% \end{figure}


\section{Using subsets}
It is quite common to want to run a linear model on only a subset of
the data. This can be quite easily accomplished in \texttt{mincLm}
using an extra subsetting specification:

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
vs <- mincLm(Filename ~ Gender, gf, coil==1)
vs
@ 

This is the same linear model command as executed above, but this time
using only use mice scanned on RF coil number 1. The subset command
works exactly the same way as for the standard \texttt{lm} command
from R.


\section{Multiple Comparisons}
The example below illustrates the entire process involved in 
running a linear model and correcting for multiple comparisons using
the False Discovery Rate.

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
vs <- mincLm(Filename ~ Gender, gf)
print(vs)
#
qvals <- mincFDR(vs, mask="volumes/mask.mnc", method="pFDR")
print(qvals)
#
fileOut <- file.path("/tmp", "Gender-FDR.mnc")
mincWriteVolume(qvals, fileOut, "GenderMale")
@ 

The first command computes a linear model using \texttt{mincLm}. The
results are then passed on to \texttt{mincFDR}, which computes the
False Discovery Rate threshold separately for each of the terms in the
linear model. Only results from within the mask specified as an
optional argument to \texttt{mincFDR} are considered. The thresholds
detected at different levels (0.01, 0.05, 0.10, 0.15, and 0.20) are
then printed out. In this example seen above there is no data at a FDR
level of 0.01, 0.05, or 0.10, but any t-statistic greater than 2.96
(or less than -2.96) would be significant at a 15\% false positive
level - i.e. 15\% of the voxels above that threshold would be, on
average, false positives. The ``GenderMale'' column is then written to
file. Note that we use the positive false discovery rate above - the
more standard false discovery rate is the default (i.e. if no method
argument is specified for \texttt{mincFDR}).

You can also compute the FDR from a volume that has already been
written to file: 

<<echo=TRUE, keep.source=TRUE, eval=TRUE>>=
setwd(dataDir)
volname <-file.path("/tmp", "simple-lm.mnc")
volume <- mincGetVolume(volname)
#
qvals <- mincFDR(volume, df=21, statType="t")
print(qvals)
@

Notice how in this case you have to specify the degrees of freedom,
since the information associated with the linear model is lost after
writing to file.  Also note that the \texttt{statType} argument is required to inform the FDR
functions that the FDR is to be computed on t-statistics (options are "t", and "F").



\chapter{Bits and Pieces}

\section{Correlations}

\section{non-parametric statistics}

\section{mixed effects models}

\section{Cleaning up}



\chapter{Advanced Topics}

\section{Running arbitrary R functions}
RMINC has the capacity to run arbitrary R functions at ever voxel of a
set of files. This comes in quite handy when there are no easily
wrapped functions that exist in RMINC but there is some existing R
module you would like to try out. Some words of caution are in order,
however:

\begin{itemize}
\item Running arbitrary functions involves writing your own small R
  function to wrap the code you want to use, which is a bit ugly.
\item It is slow. Slower than molasses on a cold Georgia winter
  morning.
\end{itemize}

Here's an example of how it works:

<<echo=TRUE, keep.source=TRUE, eval=FALSE>>=
f <- function() {
  return(tapply(x, gf$Genotype, mean))
}
vs <- mincApply(gf$jacobians, quote(f()), mask="small-mask.mnc")
@ 

The code above has two parts. The first is creating the function,
which has the following properties:

\begin{itemize}
\item It takes no arguments.
\item It works on the variable \textit{x}. This function will be
  evaluated at every voxel, where \textit{x} will be a vector
  containing the values at that voxel for all the files.
\item It returns a vector.
\end{itemize}



\printindex

\end{document}
